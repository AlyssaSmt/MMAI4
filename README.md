# MMAI ‚Äì Open Vocabulary Montagsmaler üé®ü§ñ

Ein Zeichen-Spiel mit KI:  
Du zeichnest auf einem Canvas und eine **Open-Vocabulary-KI (OpenCLIP)** versucht zu erraten, was du gemalt hast.  
Es gibt Live-Prediction (optional), zuf√§llige Zeichen-Prompts aus dem Vokabular und eine Galerie zum Speichern der Zeichnungen.

---

## Funktionen

- ‚úèÔ∏è Zeichnen auf Canvas
- ü§ñ KI-Erkennung (Open Vocabulary, keine festen Klassen)
- üëÅ Live-Prediction (ein/aus schaltbar)
- üé≤ Zuf√§lliges Zeichen-Prompt aus `vocab.txt`
- üîÄ Shuffle-Button f√ºr neues Wort
- üíæ Galerie mit gespeicherten Zeichnungen (LocalStorage)
- üóëÔ∏è L√∂schen einzelner Galerie-Eintr√§ge

---

## Voraussetzungen

- **Python 3.10 ‚Äì 3.12** (empfohlen)
- **pip**
- Optional: **Git**

> Hinweis:  
> Python 3.13 kann bei ML-Bibliotheken Probleme machen.  
> Falls etwas nicht installiert werden kann, nutze Python 3.11 oder 3.12.

---
## Konzept / Erkl√§rung (kurz)

Dieses Projekt nutzt **Open-Vocabulary-Erkennung** mit **OpenCLIP**:
- Es gibt **keine festen Klassen** wie bei einem klassisch trainierten CNN.
- Stattdessen wird die Zeichnung mit **Textbeschreibungen aus `vocab.txt`** verglichen.
- Die KI berechnet √Ñhnlichkeiten zwischen Bild-Embedding und Text-Embeddings und gibt die wahrscheinlichsten Begriffe zur√ºck.

Zusatzfeatures:
- **Live-Prediction** ist bewusst gedrosselt, da OpenCLIP pro Vorhersage viele Textvergleiche berechnet.
- Ein **Prompt-Wort** wird zuf√§llig aus dem Vokabular gew√§hlt und dient nur als Zeichenhilfe (nicht als feste Klasse).

---

## bash:

### 1. Virtuelle Umgebung erstellen und starten
```bash
python -m venv .venv
.venv\Scripts\activate  (mac: source .venv/bin/activate)
```

### 2. Abh√§ngigkeiten installieren
```
pip install -r requirements.txt
```

### 3. Backend starten (FastAPI)
```
uvicorn backend.main:app --reload --port 8001
```
Test (optional):
    Browser √∂ffnen:
    http://127.0.0.1:8001/docs

### 4. Frontend starten
```
frontend/index.html
```



open vocabulary
ganze clip library verwenden
website verbessern, das es genauer/verst√§ndlicher ist












Musste neu trainieren, weil es immer alles als string bean gesehen hat, hab dann string bean gel√∂scht

ebenfalls falsche daten benutzt, die nicht nur das bild sondern auch viel freiraum hatten.


Nicht alle Klassen sind f√ºr kleine CNNs geeignet.
Klassen mit √§hnlicher geometrischer Struktur
f√ºhrten zu systematischen Fehlklassifikationen.
Durch gezielte Klassenselektion mit hoher visueller Varianz
konnte das Modell stabilisiert werden

sehr limitiert, da es immer nur das gleiche err√§t