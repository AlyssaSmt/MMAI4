# MMAI â€“ Open Vocabulary Montagsmaler ğŸ¨ğŸ¤–

Ein Zeichen-Spiel mit KI:  
Du zeichnest auf einem Canvas und eine **Open-Vocabulary-KI (OpenCLIP)** versucht zu erraten, was du gemalt hast.  
Es gibt Live-Prediction (optional), zufÃ¤llige Zeichen-Prompts aus dem Vokabular und eine Galerie zum Speichern der Zeichnungen.

---

## Funktionen

- âœï¸ Zeichnen auf Canvas
- ğŸ¤– KI-Erkennung (Open Vocabulary, keine festen Klassen)
- ğŸ‘ Live-Prediction (ein/aus schaltbar)
- ğŸ² ZufÃ¤lliges Zeichen-Prompt aus `vocab.txt`
- ğŸ”€ Shuffle-Button fÃ¼r neues Wort
- ğŸ’¾ Galerie mit gespeicherten Zeichnungen (LocalStorage)
- ğŸ—‘ï¸ LÃ¶schen einzelner Galerie-EintrÃ¤ge

---

## Voraussetzungen

- **Python 3.10 â€“ 3.12** (empfohlen)
- **pip**
- Optional: **Git**

> Hinweis:  
> Python 3.13 kann bei ML-Bibliotheken Probleme machen.  
> Falls etwas nicht installiert werden kann, nutze Python 3.11 oder 3.12.

---
## Konzept / ErklÃ¤rung (kurz)

Dieses Projekt nutzt **Open-Vocabulary-Erkennung** mit **OpenCLIP**:
- Es gibt **keine festen Klassen** wie bei einem klassisch trainierten CNN.
- Stattdessen wird die Zeichnung mit **Textbeschreibungen aus `vocab.txt`** verglichen.
- Die KI berechnet Ã„hnlichkeiten zwischen Bild-Embedding und Text-Embeddings und gibt die wahrscheinlichsten Begriffe zurÃ¼ck.

Zusatzfeatures:
- **Live-Prediction** ist bewusst gedrosselt, da OpenCLIP pro Vorhersage viele Textvergleiche berechnet.
- Eine **Confidence-Ampel (ğŸ”´ğŸŸ¡ğŸŸ¢)** visualisiert die Unsicherheit.
- Ein **Prompt-Wort** wird zufÃ¤llig aus dem Vokabular gewÃ¤hlt und dient nur als Zeichenhilfe (nicht als feste Klasse).

---

## bash:

### 1. Virtuelle Umgebung erstellen
```bash
python -m venv .venv

### 2. .venv\Scripts\activate  (mac: source .venv/bin/activate)

### 3. AbhÃ¤ngigkeiten installieren

    pip install -r requirements.txt


### 4. Backend starten (FastAPI)

    uvicorn backend.main:app --reload --port 8001

Test (optional):
    Browser Ã¶ffnen:
    http://127.0.0.1:8001/docs

### 5. Frontend starten
    frontend/index.html



open vocabulary
ganze clip library verwenden
website verbessern, das es genauer/verstÃ¤ndlicher ist












Musste neu trainieren, weil es immer alles als string bean gesehen hat, hab dann string bean gelÃ¶scht

ebenfalls falsche daten benutzt, die nicht nur das bild sondern auch viel freiraum hatten.


Nicht alle Klassen sind fÃ¼r kleine CNNs geeignet.
Klassen mit Ã¤hnlicher geometrischer Struktur
fÃ¼hrten zu systematischen Fehlklassifikationen.
Durch gezielte Klassenselektion mit hoher visueller Varianz
konnte das Modell stabilisiert werden

sehr limitiert, da es immer nur das gleiche errÃ¤t